{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613e02ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1949c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision, Recall, and F1-score\n",
    "def get_prf1_score(y_true, y_pred):\n",
    "    tp, fp, fn = 0.0, 0.0, 0.0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            tp += 1\n",
    "        elif y_pred[i] > y_true[i]:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    if tp == 0:\n",
    "        tp = 1.0\n",
    "    if fp == 0:\n",
    "        fp = 1.0\n",
    "    if fn == 0:\n",
    "        fn  = 1.0\n",
    "    P = tp / (tp + fp)\n",
    "    R = tp / (tp + fn)\n",
    "    F = 2 * P * R / (P + R)\n",
    "    print ('\\nPrecision: {0}\\t Recall: {1}\\t F1-Score: {2}'.format(P, R, F))\n",
    "    return {'P': P, 'R': R, 'F': F}\n",
    "\n",
    "###new added file\n",
    "def oe_score(y_true, y_pred):\n",
    "    oe_no=0\n",
    "    nt=len(y_pred)\n",
    "    for i in range(nt):\n",
    "        if abs(y_pred[i]-y_true[i])>1:\n",
    "            oe_no+=1\n",
    "    OE= oe_no/nt\n",
    "    print('OE:{}'.format(OE))\n",
    "    return {'OE': OE}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df94f8",
   "metadata": {},
   "source": [
    "### Test the precision, Recall, F1-score, OE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6377c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: 0.75\t Recall: 0.6\t F1-Score: 0.6666666666666665\n",
      "OE:0.16666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'P': 0.75, 'R': 0.6, 'F': 0.6666666666666665}, {'OE': 0.16666666666666666})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true,y_pred=[0,1,2,2,4,3],[0,1,4,2,3,2]\n",
    "get_prf1_score(y_true, y_pred),oe_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c31fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###unzip the file\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "path=r'C:\\GAOMSA_Comb\\OMSA_Summer_2021_and_later\\Spring2022\\CSE6250\\BHDProject\\Project\\Suicide-Severity\\conceptnet-numberbatch-master'\n",
    "os.chdir(path)\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "f_in=open\n",
    "with gzip.open('numberbatch-en-19.08.txt.gz', 'rb') as f_in:\n",
    "    with open('numberbatch-en.txt','wb') as f_out:\n",
    "        shutil.copyfileobj(f_in,f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5697b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###test vectorize_data()\n",
    "import csv\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import datetime, time\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input, MaxPool2D\n",
    "from keras.layers import Conv2D, GlobalAveragePooling1D, MaxPooling2D\n",
    "from keras.layers import Concatenate\n",
    "# from keras.optimizers import Adam\n",
    "# https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c006db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_params = {'emb_dim': 300,\n",
    "              'max_sent_len': 1500,\n",
    "              'str_padd': '@PADD',\n",
    "              'cross_val': 5}\n",
    "w2v_file = {'file': 'numberbatch-en.txt', 'is_binary': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1859b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the input data using pretrained word2vec embedding lookup\n",
    "def vectorize_data(lst_input):\n",
    "\n",
    "    padd = sys_params['str_padd']\n",
    "    wv_size = sys_params['emb_dim']\n",
    "\n",
    "    # Load the pre-trained word2vec model\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(w2v_file['file'], binary=w2v_file['is_binary'])\n",
    "\n",
    "    # Get the word2vec vocabulary\n",
    "    # vocab = w2v_model.vocab  ##out of date\n",
    "    vocab =w2v_model.key_to_index\n",
    "    #\n",
    "    padding_zeros = np.zeros(wv_size, dtype=np.float32)\n",
    "\n",
    "    x_data = []\n",
    "\n",
    "    # Loop through each sentence\n",
    "    for sent in lst_input:\n",
    "        emb = []\n",
    "        for tok in sent:\n",
    "\n",
    "            # # Zero-padding for padded tokens\n",
    "            # if tok == padd:\n",
    "            #     emb.append(list(padding_zeros))\n",
    "\n",
    "            # # Get the token embedding from the word2vec model\n",
    "            # elif tok in vocab.keys():\n",
    "            #     emb.append(w2v_model[tok].astype(float).tolist())\n",
    "            # Zero-padding for padded tokens\n",
    "            if tok.lower() == padd:\n",
    "                emb.append(list(padding_zeros))\n",
    "\n",
    "            # Get the token embedding from the word2vec model\n",
    "            elif tok.lower() in vocab.keys():\n",
    "                emb.append(w2v_model[tok.lower()].astype(float).tolist())\n",
    "            # Zero-padding for out-of-vocab tokens\n",
    "            else:\n",
    "                emb.append(list(padding_zeros))\n",
    "\n",
    "        x_data.append(emb)\n",
    "\n",
    "    del w2v_model, vocab\n",
    "\n",
    "    return np.array(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b26cd",
   "metadata": {},
   "source": [
    "### Make sure the lst_input format to be a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d74659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.1129    , -0.14210001,  0.0169    , ...,  0.0227    ,\n",
       "          0.0246    ,  0.0084    ],\n",
       "        [-0.0615    , -0.1116    , -0.03      , ..., -0.0007    ,\n",
       "          0.0232    , -0.0141    ],\n",
       "        [-0.1011    , -0.0806    , -0.0092    , ...,  0.0398    ,\n",
       "         -0.0122    , -0.0257    ],\n",
       "        [-0.0715    ,  0.0022    ,  0.0066    , ...,  0.0061    ,\n",
       "          0.0114    , -0.0099    ]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###example to use vectorize_data()\n",
    "vectorize_data([[\"I\",\"am\",\"a\",\"robot\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
